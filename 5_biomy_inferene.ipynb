{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_biomy_inferene.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VvbkCyoptKC"
      },
      "source": [
        "### Biomy社むけのipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh0XOYGrwLZH"
      },
      "source": [
        "#### STEP (0)\n",
        "*   必要なモジュールをインストール\n",
        "*   condaを利用して、オリジナルのenvironment.ymlを実行する場合は、segmentation-modelsのみでOK\n",
        "*   モデルは[ここ](https://github.com/hasibzunair/MoNuSAC-ISBI-2020/releases/tag/v0.0.1)からDLしておく必要あり、保存先のディレクトリは変数MODEL_PATHにおく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsUHta-YwQ3V"
      },
      "source": [
        "!apt-get install openslide-tools\n",
        "!apt-get install python-openslide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8c3wGBewOa2"
      },
      "source": [
        "!pip install openslide-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56C1Deh9wcNL"
      },
      "source": [
        "# README.mdでは文中”NOTE”に記載があるので注意\n",
        "!pip install segmentation-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqbYnHzbqAvZ"
      },
      "source": [
        "\n",
        "\n",
        "#### STEP (1)\n",
        "svs/ndpi/tif等のWSIを以下のフォルダ構成(階層)のように格納すること\n",
        "\n",
        "---\n",
        "```\n",
        "DATA\n",
        "├── CONTAIN\n",
        "│   ├── SUBJECT_1\n",
        "│   ├── SUBJECT_2\n",
        "│   ├── ...\n",
        "│   └── SUBJECT_N\n",
        "│       └── WSI.ndpi\n",
        "│\n",
        "└── UNCONTAIN\n",
        "    ├── SUBJECT_1\n",
        "    ├── SUBJECT_2\n",
        "    ├── ...\n",
        "    └── SUBJECT_M\n",
        "        └── WSI.ndpi\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WW9Jt8Gpk3Y"
      },
      "source": [
        "import openslide\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "import os \n",
        "import time\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import skimage.draw\n",
        "import random\n",
        "import keras\n",
        "from skimage.transform import resize\n",
        "from skimage.segmentation import watershed\n",
        "from skimage.feature import peak_local_max\n",
        "import skimage.io\n",
        "import efficientnet.tfkeras\n",
        "from tensorflow.keras.models import load_model\n",
        "from scipy import ndimage as ndi\n",
        "from PIL import Image, ImagePalette\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "NUCLEI_PALETTE = ImagePalette.random()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW4mxI-H_fHN"
      },
      "source": [
        "# 事前にDLした学習済みモデルの読み込み\n",
        "MODEL_PATH = 'PRETRAINED_MODEL_PATH'\n",
        "MODEL = load_model('{}/unet_efficientnetb3_multiclass.h5'.format(MODEL_PATH), compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq7kCuRezMvP"
      },
      "source": [
        "#### STEP (2)\n",
        "WSIを細切れにクロップする。<br>\n",
        "適当な閾値によって細胞が多いところにあたりをつけているので、すべての領域を実施する場合は、変数を以下に設定すること。\n",
        "```\n",
        "THRESH=255　　# 255のときは真っ白\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GOJkF6C0ded"
      },
      "source": [
        "# 変数の設定\n",
        "BASE = Path('DATA')\n",
        "DATA_SETNAME = 'test_images'  # 細切れにした画像の保存先フォルダ名\n",
        "SAVE_BASE = BASE.joinpath(DATA_SETNAME)\n",
        "THRESH = 70\n",
        "NUM_CREATE = 10  # クロップする画像数\n",
        "CROP_W, CROP_H = 96, 96\n",
        "LEVEL = 0  # WSIのレベル指定\n",
        "TARGET_DIR = 'CONTAIN'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ExPUkhzL90"
      },
      "source": [
        "np.random.seed(0)  # 検証のためシード固定\n",
        "\n",
        "def split_img_thumbnail(nih_base, get_type, w=512, h=512):\n",
        "    for subject_id_dir in [dir_path for dir_path in BASE.joinpath(get_type).iterdir() if dir_path.is_dir()]:\n",
        "        svs_path = [svs for svs in subject_id_dir.iterdir()][0]  # SUBJECT_Xのフォルダ以下には1枚しかない場合を仮定してインデックス0を指定\n",
        "        # print(svs_path.stem)\n",
        "        try:\n",
        "            print('*'*30)\n",
        "            csvs_slide = openslide.OpenSlide(str(svs_path))\n",
        "\n",
        "            # サムネイル画像つかってクロップ領域を確認\n",
        "            k = csvs_slide.get_thumbnail((w,h))\n",
        "            gray_k = k.convert('L')\n",
        "            # サムネイルで画素値のヒストグラムをみて、細胞画像に当てをつける\n",
        "            v = 255 - np.array(gray_k)\n",
        "            thresh_idx = v > THRESH\n",
        "            idx_xy = np.where(thresh_idx)\n",
        "            num_cell = np.shape(idx_xy)[1]\n",
        "            dice = list(range(0, num_cell-1))  # 0からあたりをつけた細胞画像数までのサイコロ作成\n",
        "            # テスト時のようにNUM_CREATEが小さいときは、重複は起こりにくいが、np.random.sample(dice, NUM_CREATE)なら被らない\n",
        "            select_idxs = np.random.choice(dice, NUM_CREATE)\n",
        "            for select_idx in select_idxs:\n",
        "                # print(select_idx)\n",
        "                x,y = np.array(idx_xy)[:, select_idx]\n",
        "                rate_x, rate_y = csvs_slide.dimensions[0]/h, csvs_slide.dimensions[1]/w\n",
        "                print('Top　Left=({},{})'.format(x, y))\n",
        "                print('Showing Resize Rate={}'.format(rate_x**(-1)))\n",
        "\n",
        "                # 左上の座標によって枠外が発生する可能性あるので注意、以下は何も手当てしていない\n",
        "                ox, oy = int(x*rate_x), int(y*rate_y)\n",
        "                crop_img = csvs_slide.read_region((oy, ox), LEVEL, (CROP_W, CROP_H))\n",
        "\n",
        "                # サムネイズ画像のなかで、ざっくりどの辺りをクロップしているか確認\n",
        "                tmp_k = k.copy()\n",
        "                draw = ImageDraw.Draw(tmp_k)\n",
        "                draw.rectangle((y, x,\n",
        "                                y+int(rate_y**(-1)*1000), x+int(rate_x**(-1)*1000)),\n",
        "                                outline=(255, 0, 0), width=10)\n",
        "                fig = plt.figure()\n",
        "                ax = fig.add_subplot(1,2,1)\n",
        "                ax.imshow(tmp_k)\n",
        "                ax.axis(False)\n",
        "\n",
        "                # クロップ画像を指定レベルで確認\n",
        "                ax = fig.add_subplot(1,2,2)\n",
        "                ax.imshow(crop_img)\n",
        "                plt.title(svs_path.stem.split('.')[-1])\n",
        "                ax.axis(False)\n",
        "                plt.show()\n",
        "\n",
        "                # save as png\n",
        "                if not SAVE_BASE.joinpath(svs_path.stem).exists():\n",
        "                    SAVE_BASE.joinpath(svs_path.stem, 'images').mkdir(parents=True)\n",
        "                crop_rgb_img = crop_img.convert('RGB')\n",
        "                save_at = SAVE_BASE.joinpath(svs_path.stem, 'images', '{}_{}.jpg'.format(ox,oy))\n",
        "                crop_rgb_img.save(str(save_at))\n",
        "\n",
        "            '''\n",
        "            # 1d ヒストグラムは閾値をざっくりみたかっただけ\n",
        "            plt.figure()\n",
        "            sns.distplot(v)  # 背景白が255になるため\n",
        "            plt.show()\n",
        "            '''\n",
        "        except:\n",
        "            print('missing to load the file:{}'.format(svs_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1PeIH1G0awu"
      },
      "source": [
        "split_img_thumbnail(BASE, TARGET_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUPweiqo8-SQ"
      },
      "source": [
        "#### STEP (3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5gZ6UMV7Cht"
      },
      "source": [
        "# Define paths\n",
        "TEST_DATASET_PATH = os.path.join(BASE, DATA_SETNAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hihgkxS37Cnu"
      },
      "source": [
        "def create_directory(directory):\n",
        "    '''\n",
        "    Creates a new folder in the specified directory if the folder doesn't exist.\n",
        "    INPUT\n",
        "        directory: Folder to be created, called as \"folder/\".\n",
        "    OUTPUT\n",
        "        New folder in the current directory.\n",
        "    '''\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25ZfIF8f9U65"
      },
      "source": [
        "def pad(img, pad_size=96):\n",
        "    \"\"\"\n",
        "    Load image from a given path and pad it on the sides, so that eash side is divisible by 96 (network requirement)\n",
        "    if pad = True:\n",
        "        returns image as numpy.array, tuple with padding in pixels as(x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
        "    else:\n",
        "        returns image as numpy.array\n",
        "    \"\"\"\n",
        "\n",
        "    if pad_size == 0:\n",
        "        return img\n",
        "\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    if height % pad_size == 0:\n",
        "        y_min_pad = 0\n",
        "        y_max_pad = 0\n",
        "    else:\n",
        "        y_pad = pad_size - height % pad_size\n",
        "        y_min_pad = int(y_pad / 2)\n",
        "        y_max_pad = y_pad - y_min_pad\n",
        "\n",
        "    if width % pad_size == 0:\n",
        "        x_min_pad = 0\n",
        "        x_max_pad = 0\n",
        "    else:\n",
        "        x_pad = pad_size - width % pad_size\n",
        "        x_min_pad = int(x_pad / 2)\n",
        "        x_max_pad = x_pad - x_min_pad\n",
        "\n",
        "    img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad, x_min_pad, x_max_pad, cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    return img, (x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
        "\n",
        "\n",
        "def unpad(img, pads):\n",
        "    \"\"\"\n",
        "    img: numpy array of the shape (height, width)\n",
        "    pads: (x_min_pad, y_min_pad, x_max_pad, y_max_pad)\n",
        "    @return padded image\n",
        "    \"\"\"\n",
        "    (x_min_pad, y_min_pad, x_max_pad, y_max_pad) = pads\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    return img[y_min_pad:height - y_max_pad, x_min_pad:width - x_max_pad]\n",
        "\n",
        "\n",
        "def read_nuclei(path):\n",
        "    \"read raw data\"\n",
        "\n",
        "    # Load 4-channel image\n",
        "    img = skimage.io.imread(path)\n",
        "    \n",
        "    # input image\n",
        "    if len(img.shape) > 2:\n",
        "        img = img[:,:,:3]\n",
        "    # mask\n",
        "    else:\n",
        "        # do nothing\n",
        "        pass\n",
        "        \n",
        "    return img\n",
        "\n",
        "\n",
        "def save_nuclei(path, img):\n",
        "    \"save image\"\n",
        "    skimage.io.imsave(path, img)\n",
        "\n",
        "    \n",
        "def sliding_window(image, step, window):\n",
        "    x_loc = []\n",
        "    y_loc = []\n",
        "    cells = []\n",
        "    \n",
        "    for y in range(0, image.shape[0], step):\n",
        "        for x in range(0, image.shape[1], step):\n",
        "            cells.append(image[y:y + window[1], x:x + window[0]])\n",
        "            x_loc.append(x)\n",
        "            y_loc.append(y)\n",
        "    return x_loc, y_loc, cells\n",
        "\n",
        "\n",
        "def extract_patches(image, step, patch_size):    \n",
        "    patches = []\n",
        "    \n",
        "    # Get locations\n",
        "    x_pos, y_pos, cells = sliding_window(image, step, (patch_size[0], patch_size[1]))\n",
        "\n",
        "    for (x, y, cell) in zip(x_pos, y_pos, cells):\n",
        "\n",
        "        # Get patch\n",
        "        patch = image[y:y + patch_size[0], x:x + patch_size[0]]\n",
        "\n",
        "        # Get size\n",
        "        raw_dim = (patch.shape[1], patch.shape[0]) # W, H\n",
        "        #print(raw_dim)\n",
        "        #print(patch.shape)\n",
        "\n",
        "\n",
        "        if raw_dim != (patch_size[0], patch_size[1]):\n",
        "\n",
        "            # Resize to 64x64\n",
        "            #patch = cv2.resize(patch, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "            patch, pad_locs = pad(patch, pad_size=patch_size[0])\n",
        "            \n",
        "            \n",
        "            # Do stuffffff\n",
        "            patches.append(patch)\n",
        "        \n",
        "        else:\n",
        "\n",
        "            # Do stuffffff\n",
        "            patches.append(patch)\n",
        "    \n",
        "    patches = np.array(patches)\n",
        "    \n",
        "    return patches\n",
        "    \n",
        "# Compute Panoptic quality metric for each image\n",
        "def Panoptic_quality(ground_truth_image,predicted_image):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    sum_IOU = 0\n",
        "    matched_instances = {}# Create a dictionary to save ground truth indices in keys and predicted matched instances as velues\n",
        "                        # It will also save IOU of the matched instance in [indx][1]\n",
        "\n",
        "    # Find matched instances and save it in a dictionary\n",
        "    for i in np.unique(ground_truth_image):\n",
        "        if i == 0:\n",
        "            pass\n",
        "        else:\n",
        "            temp_image = np.array(ground_truth_image)\n",
        "            temp_image = temp_image == i\n",
        "            matched_image = temp_image * predicted_image\n",
        "        \n",
        "            for j in np.unique(matched_image):\n",
        "                if j == 0:\n",
        "                    pass\n",
        "                else:\n",
        "                    pred_temp = predicted_image == j\n",
        "                    intersection = sum(sum(temp_image*pred_temp))\n",
        "                    union = sum(sum(temp_image + pred_temp))\n",
        "                    IOU = intersection/union\n",
        "                    if IOU> 0.5:\n",
        "                        matched_instances [i] = j, IOU \n",
        "                        \n",
        "    # Compute TP, FP, FN and sum of IOU of the matched instances to compute Panoptic Quality               \n",
        "                        \n",
        "    pred_indx_list = np.unique(predicted_image)\n",
        "    pred_indx_list = np.array(pred_indx_list[1:])\n",
        "\n",
        "    # Loop on ground truth instances\n",
        "    for indx in np.unique(ground_truth_image):\n",
        "        if indx == 0:\n",
        "            pass\n",
        "        else:\n",
        "            if indx in matched_instances.keys():\n",
        "                pred_indx_list = np.delete(pred_indx_list, np.argwhere(pred_indx_list == [indx][0]))\n",
        "                TP = TP+1\n",
        "                sum_IOU = sum_IOU+matched_instances[indx][1]\n",
        "            else:\n",
        "                FN = FN+1\n",
        "    FP = len(np.unique(pred_indx_list))\n",
        "    PQ = sum_IOU/(TP+0.5*FP+0.5*FN)\n",
        "    \n",
        "    return PQ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv4eHZEY9U9Z"
      },
      "source": [
        "# SAME CODE BLOCK AS IN 6_inference.ipynb\n",
        "# Helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"Plot images in one row.\"\"\"\n",
        "    \n",
        "    norm=plt.Normalize(0,4) # 5 classes including BG\n",
        "    map_name = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\", \"red\",\"yellow\",\"blue\", \"green\"])\n",
        "\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(18, 16))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image, cmap=map_name, norm=norm)\n",
        "    plt.show()\n",
        "    \n",
        "        \n",
        "def prep(img):\n",
        "    img = img.astype('float32')\n",
        "    img = (img > 0.5).astype(np.uint8)  # threshold\n",
        "    img = resize(img, (image_cols, image_rows), preserve_range=True)\n",
        "    return img\n",
        "\n",
        "\n",
        "def visualize_results(image, mask):\n",
        "    \n",
        "    f, axarr = plt.subplots(1,2, figsize=(16, 16))\n",
        "    \n",
        "    norm=plt.Normalize(0,4) # 5 classes including BG\n",
        "    map_name = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\", \"red\",\"yellow\",\"blue\", \"green\"])\n",
        "\n",
        "    axarr[0].imshow(image)\n",
        "    axarr[1].imshow(mask, cmap=map_name, norm=norm)\n",
        "\n",
        "\n",
        "def vis_gray(image, mask):\n",
        "    \n",
        "    f, axarr = plt.subplots(1,2, figsize=(16, 16))\n",
        "    \n",
        "    axarr[0].imshow(image)\n",
        "    axarr[1].imshow(mask, cmap='gray')\n",
        "\n",
        "\n",
        "def predict(im):\n",
        "    \"\"\"Predict on patch\"\"\"\n",
        "    im = np.expand_dims(im, axis=0)\n",
        "    # WARNING、元のコードはグローバル変数のモデルを利用している\n",
        "    im = MODEL.predict(im)\n",
        "    # im = model.predict(im)\n",
        "    im = np.argmax(im.squeeze(), axis=-1)\n",
        "    #assert im.shape == (96, 96), \"Wrong shape, {}!\".format(im.shape)    \n",
        "    return im\n",
        "\n",
        "\n",
        "def instance_seg(image):\n",
        "    distance = ndi.distance_transform_edt(image)\n",
        "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)), labels=image)\n",
        "    markers = ndi.label(local_maxi)[0]\n",
        "    labels = watershed(-distance, markers, mask=image)\n",
        "    return labels    \n",
        "\n",
        "\n",
        "\n",
        "def whole_slide_predict(whole_image):\n",
        "    #import pdb; pdb.set_trace()    \n",
        "    # If input image less than patch, infer on whole image\n",
        "    if whole_image.shape[0] < 96 or whole_image.shape[1] < 96:\n",
        "        # Get size\n",
        "        raw_dim = (whole_image.shape[1], whole_image.shape[0]) # W, H\n",
        "        \n",
        "        # Resize to 64x64 for prediction\n",
        "        #whole_image_rs = cv2.resize(whole_image, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "        whole_image_rs, pad_locs = pad(whole_image, pad_size=96)\n",
        "        # Infer\n",
        "        pred = predict(whole_image_rs)        \n",
        "        # Resize back to original shape\n",
        "        #pred = cv2.resize(pred, raw_dim, interpolation = cv2.INTER_AREA)\n",
        "        pred = unpad(pred, pad_locs)\n",
        "        # Change dtype for resizing back to original shape\n",
        "        pred = pred.astype(np.uint8)\n",
        "    else:\n",
        "        # Get patch locations\n",
        "        x_pos, y_pos, cells = sliding_window(whole_image, 96, (96, 96)) \n",
        "        # Array for storing predictions\n",
        "        pred = np.zeros((whole_image.shape[0], whole_image.shape[1])).astype(np.uint8)\n",
        "\n",
        "        # Slide over each patch\n",
        "        for (x, y, cell) in zip(x_pos, y_pos, cells):\n",
        "            # Get patch\n",
        "            patch = whole_image[y:y + 96, x:x + 96]\n",
        "            # Get size\n",
        "            raw_dim = (patch.shape[1], patch.shape[0]) # W, H\n",
        "            # If less than patch size, resize and then run prediction\n",
        "            # print('kokomadeha?')\n",
        "            if raw_dim != (96, 96):\n",
        "                # Resize to 64x64\n",
        "                #patch_rs = cv2.resize(patch, (64, 64), interpolation = cv2.INTER_AREA)\n",
        "                patch_rs, pad_locs = pad(patch, pad_size=96)                \n",
        "                #print(patch.dtype, processed.dtype)\n",
        "                assert patch.dtype == patch_rs.dtype, \"Wrong data type after resizing!\"\n",
        "                # Infer\n",
        "                processed = predict(patch_rs)\n",
        "                \n",
        "                # Resize back to original shape\n",
        "                #processed = cv2.resize(processed, raw_dim, interpolation = cv2.INTER_AREA)\n",
        "                processed = unpad(processed, pad_locs)\n",
        "                \n",
        "                # Change dtype \n",
        "                processed = processed.astype(np.uint8)\n",
        "                \n",
        "                assert patch.shape[:2] == processed.shape, \"Wrong shape!\"\n",
        "                assert patch.dtype == processed.dtype, \"Wrong data type in prediction!\"\n",
        "\n",
        "            else:\n",
        "                # print('kocchiyane')\n",
        "                # Infer\n",
        "                processed = predict(patch)\n",
        "                # Change dtype\n",
        "                processed = processed.astype(np.uint8)\n",
        "                #print(patch.dtype, processed.dtype)\n",
        "                assert patch.shape[:2] == processed.shape, \"Wrong shape!\"\n",
        "                assert patch.dtype == processed.dtype, \"Wrong data type in prediction!\"\n",
        "\n",
        "            # Add in image variable\n",
        "            pred[y:y + 96, x:x + 96] = processed \n",
        "            processed = None\n",
        "\n",
        "    return pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8gBr7tj9iwe"
      },
      "source": [
        "#### STEP (4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5KpQP3X9U_n"
      },
      "source": [
        "for subject_dir in Path(TEST_DATASET_PATH).iterdir():\n",
        "    for img_dir in subject_dir.iterdir():\n",
        "        image_fns = sorted([img_path for img_path in img_dir.glob('**/*')])\n",
        "        for idx in range(len(image_fns)):\n",
        "            print(\"Index: \",idx)\n",
        "            # print(Path(os.path.join(test_dataset_path, image_fns[idx])).exists())\n",
        "            image = skimage.io.imread(os.path.join(TEST_DATASET_PATH, image_fns[idx]))\n",
        "            print(\"Image shape:\", image.shape)\n",
        "\n",
        "            pred = whole_slide_predict(image)\n",
        "            print(pred.dtype)\n",
        "            # Post processing to refine predictions\n",
        "            pred_filt = cv2.medianBlur(pred.astype(np.uint8), 5)\n",
        "\n",
        "            print(image.shape, pred.shape)\n",
        "            print(\"Uniques predicted\", np.unique(pred))\n",
        "            # 順番は別のipynbを信じてみた\n",
        "            label_map = {\n",
        "                        '0':'background',\n",
        "                        '1':'Epithelial',\n",
        "                        '2':'Lymphocyte',\n",
        "                        '4':'Macrophage',\n",
        "                        '3':'Neutrophil',\n",
        "                    }\n",
        "            print([label_map[str(i)]for i in np.unique(pred)])\n",
        "            assert image.shape[:2] == pred.shape, \"Image missmatch\"\n",
        "\n",
        "            #visualize_results(image, pred)\n",
        "\n",
        "            visualize(\n",
        "                    image=image,\n",
        "                    Predicted_mask = pred,\n",
        "                    Filtered_mask = pred_filt\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}